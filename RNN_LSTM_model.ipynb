{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_pred.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJeBbiz2IZkJ"
      },
      "source": [
        "#  –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_kwuovnIXQe",
        "outputId": "6b44be3c-ed94-4064-b158-d122328ebb8e"
      },
      "source": [
        "# Grab Jaime's excellent condacolab package: https://github.com/jaimergp/condacolab\n",
        "# Note: you should probably read the README file at that repo.\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGx8Q2cHIdCt",
        "outputId": "d69b2f48-e915-48e9-97e8-7f8a3388849a"
      },
      "source": [
        "!mamba install -c conda-forge rdkit chembl_structure_pipeline\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                  __    __    __    __\n",
            "                 /  \\  /  \\  /  \\  /  \\\n",
            "                /    \\/    \\/    \\/    \\\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà/  /‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "              /  / \\   / \\   / \\   / \\  \\____\n",
            "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
            "            / _/                       \\_____/  `\n",
            "            |/\n",
            "        ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
            "        ‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó\n",
            "        ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë\n",
            "        ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë\n",
            "        ‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë\n",
            "        ‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù\n",
            "\n",
            "        mamba (0.8.0) supported by @QuantStack\n",
            "\n",
            "        GitHub:  https://github.com/mamba-org/mamba\n",
            "        Twitter: https://twitter.com/QuantStack\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\n",
            "\n",
            "Looking for: ['rdkit', 'chembl_structure_pipeline']\n",
            "\n",
            "conda-forge/linux-64     Using cache\n",
            "conda-forge/noarch       Using cache\n",
            "pkgs/main/noarch         [] (--:--) No change\n",
            "pkgs/main/noarch         [] (00m:00s) No change\n",
            "pkgs/main/noarch         [] (00m:00s) No change\n",
            "pkgs/main/linux-64       [] (--:--) No change\n",
            "pkgs/main/linux-64       [] (00m:00s) No change\n",
            "pkgs/main/linux-64       [] (00m:00s) No change\n",
            "pkgs/r/linux-64          [] (--:--) No change\n",
            "pkgs/r/linux-64          [] (00m:00s) No change\n",
            "pkgs/r/linux-64          [] (00m:00s) No change\n",
            "pkgs/r/noarch            [] (--:--) No change\n",
            "pkgs/r/noarch            [] (00m:00s) No change\n",
            "pkgs/r/noarch            [] (00m:00s) No change\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local\n",
            "\n",
            "  All requested packages already installed\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKYS_O42JKDf"
      },
      "source": [
        "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNi1nLT4IjIs"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, Descriptors\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from multiprocessing.pool import Pool\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "import os\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.MolStandardize.tautomer import TautomerCanonicalizer\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLOeiYNvKHbJ"
      },
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saeLyuxTJMfX",
        "outputId": "3ffda941-6334-4a4a-87fe-ec45f9afd982"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/kostyastrong/HSE_nlp_mol_properties/master/data/lipophilicity.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-09 21:49:33--  https://www.dropbox.com/s/dsrl00tj4zjmqbz/Lipophilicity.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/dsrl00tj4zjmqbz/Lipophilicity.csv [following]\n",
            "--2021-05-09 21:49:33--  https://www.dropbox.com/s/raw/dsrl00tj4zjmqbz/Lipophilicity.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com/cd/0/inline/BOJi8PHi4cL6o9RSCUx3csA_1F3ysHPm0MZFbr1EbKm9eA2BBgGSq1-cZO4r35C5pAlMhmAm5y4z13zpEqAD47toNgfGPWdod4YYKg9IvYjpW3TJeJvJ1EJSnI-2pYYDANahqIOxKIrzK5m_lmC39KNf/file# [following]\n",
            "--2021-05-09 21:49:34--  https://ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com/cd/0/inline/BOJi8PHi4cL6o9RSCUx3csA_1F3ysHPm0MZFbr1EbKm9eA2BBgGSq1-cZO4r35C5pAlMhmAm5y4z13zpEqAD47toNgfGPWdod4YYKg9IvYjpW3TJeJvJ1EJSnI-2pYYDANahqIOxKIrzK5m_lmC39KNf/file\n",
            "Resolving ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com (ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com (ucc96385079ea9be1808d03b5d24.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 282606 (276K) [text/plain]\n",
            "Saving to: ‚ÄòLipophilicity.csv‚Äô\n",
            "\n",
            "Lipophilicity.csv   100%[===================>] 275.98K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-05-09 21:49:34 (3.62 MB/s) - ‚ÄòLipophilicity.csv‚Äô saved [282606/282606]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pZTZw8PKUMN"
      },
      "source": [
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "1. –°–¥–µ–ª–∞–π—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é SMILES –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–¥ —Å TautomerCanonicalizer)\n",
        "\n",
        "2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –ø–æ—è–≤–∏–ª–∏—Å—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö SMILES. –£–¥–∞–ª–∏—Ç–µ –∏—Ö –ø—Ä–∏ –ø–æ–º–æ—â–∏ –º–µ—Ç–æ–¥–∞ drop_duplicates()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF7rtzVwCXrP"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewEvh_662YYU"
      },
      "source": [
        "data = pd.read_csv('lipophilicity.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hwt13TtKCFiO",
        "outputId": "7998090b-70c7-4ab6-a7c3-b0a4f0ba0ae5"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CMPD_CHEMBLID</th>\n",
              "      <th>exp</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHEMBL596271</td>\n",
              "      <td>3.54</td>\n",
              "      <td>Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHEMBL1951080</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHEMBL1771</td>\n",
              "      <td>3.69</td>\n",
              "      <td>COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHEMBL234951</td>\n",
              "      <td>3.37</td>\n",
              "      <td>OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHEMBL565079</td>\n",
              "      <td>3.10</td>\n",
              "      <td>Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CMPD_CHEMBLID   exp                                             smiles\n",
              "0   CHEMBL596271  3.54            Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14\n",
              "1  CHEMBL1951080 -1.18  COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...\n",
              "2     CHEMBL1771  3.69             COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl\n",
              "3   CHEMBL234951  3.37  OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...\n",
              "4   CHEMBL565079  3.10  Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djX8p8uXDorN"
      },
      "source": [
        "from typing import Dict, List, Optional\n",
        "import os\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.MolStandardize.tautomer import TautomerCanonicalizer\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class DatasetsHolder:\n",
        "    @staticmethod\n",
        "    def read_datasets(inp_folder_path):\n",
        "        Dataframe = pd.read_csv(inp_folder_path)\n",
        "        return Dataframe\n",
        "\n",
        "\n",
        "class StandardizeDatasets:\n",
        "    @staticmethod\n",
        "    def standardize_smiles(smi: str) -> Optional[str]:\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        m = Chem.MolToSmiles(m)\n",
        "        return m\n",
        "\n",
        "    def standardize(self, inp_path: Path, out_path: Path):\n",
        "        smth = DatasetsHolder()\n",
        "        data = smth.read_datasets(inp_path)\n",
        "        data['st_smiles'] = data['smiles'].apply(self.standardize_smiles)\n",
        "        data.to_csv(out_path)\n",
        "\n",
        "\n",
        "class StandardizeTautomers(StandardizeDatasets):\n",
        "    @staticmethod\n",
        "    def standardize_smiles(smi: str) -> Optional[str]:\n",
        "        tmp = TautomerCanonicalizer()\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        m = tmp.canonicalize(m)\n",
        "        return Chem.MolToSmiles(m)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "AYfaz1EnCHYF",
        "outputId": "134096bd-4558-43e2-8db3-e8e548f6ff3e"
      },
      "source": [
        "'''with Pool(10) as pool:\n",
        "    data['standartize_smiles'] = list(\n",
        "                        tqdm(pool.imap(StandardizeTautomers.standardize_smiles, data.smiles), total=data.shape[0])\n",
        "                    )'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with Pool(10) as pool:\\n    data['standartize_smiles'] = list(\\n                        tqdm(pool.imap(StandardizeTautomers.standardize_smiles, data.smiles), total=data.shape[0])\\n                    )\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xpxZj_dIqMM",
        "outputId": "dfbca2a3-ecc9-434a-ba40-830b3feee475"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq8feUj8LYF7"
      },
      "source": [
        "–í –¥–∞–Ω–Ω–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –º–æ–ª–µ–∫—É–ª–∞–º–∏ –∫–∞–∫ —Å–æ —Å—Ç—Ä–æ–∫–∞–º–∏ - —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é —Å–∏–º–≤–æ–ª–æ–≤ SMILES.\n",
        "\n",
        "–î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –Ω–µ–π—Ä–æ—Å–µ—Ç—å –º–æ–≥–ª–∞ \"–ø—Ä–æ–≥–ª–æ—Ç–∏—Ç—å\" —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏—Ö –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ –Ω–∞–±–æ—Ä —á–∏—Å–µ–ª.\n",
        "\n",
        "1. –†–∞–∑–¥–µ–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ SMILES –Ω–∞ \"—Ç–æ–∫–µ–Ω—ã\". –¢–æ–∫–µ–Ω - –æ—Ç–¥–µ–ª—å–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ —Ç–µ–∫—Å—Ç–∞, –º–æ–∂–Ω–æ –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞—Ç—å –µ–≥–æ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫.\n",
        "\n",
        "2. –°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω–∞–º –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –≤ —Å–ª–æ–≤–∞—Ä–µ.\n",
        "\n",
        "\n",
        "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Å—Ç—Ä–æ–∫–µ. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ —Ç–∞–∫–æ–π –ø–æ–∏—Å–∫ —Å–æ–≤–µ—Ä—à–∞—Ç—å –ø—Ä–∏ –ø–æ–º–æ—â–∏ [—Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π](https://docs.python.org/3/howto/regex.html).\n",
        "\n",
        "**–ó–∞–¥–∞–Ω–∏–µ**: \n",
        "1. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ SMILES –≤ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –ü–æ–¥—É–º–∞–π—Ç–µ, –∫–∞–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –∏–∑ —ç—Ç–∏—Ö —Å—Ç—Ä–æ–∫? (–∫–∞–∫–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –º–æ–ª–µ–∫—É–ª–∞—Ö, –∫–∞–∫–∏–µ —Å–ø–µ—Ü —Å–∏–º–≤–æ–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è)\n",
        "2. –ü—Ä–∏–¥—É–º–∞–π—Ç–µ pattern —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —Å–º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –Ω—É–∂–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã. (–ø–æ–¥—Å–∫–∞–∑–∫–∞ - –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —É–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —Å–∏–º–≤–æ–ª ¬†|)\n",
        "3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∫–æ –≤—Å–µ–º smiles –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDEWRvgzLkFj"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/HSE_data/norm_smiles.csv') #–ø–µ—Ä–µ–≤–µ–¥–µ–º smiles –≤ –Ω–æ—Ä–º –≤–∏–¥"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "9MYpIFu9OtHY",
        "outputId": "91a64520-b1c5-4b3c-bdfb-d1e1559c7d3c"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CMPD_CHEMBLID</th>\n",
              "      <th>exp</th>\n",
              "      <th>smiles</th>\n",
              "      <th>standartize_smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CHEMBL596271</td>\n",
              "      <td>3.54</td>\n",
              "      <td>Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14</td>\n",
              "      <td>Cn1c(CN2CCN(c3ccc(Cl)cc3)CC2)nc2ccccc21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CHEMBL1951080</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...</td>\n",
              "      <td>COc1cc(OC)c(S(=O)(=O)N2c3ccccc3CCC2C)cc1NC(=O)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CHEMBL1771</td>\n",
              "      <td>3.69</td>\n",
              "      <td>COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl</td>\n",
              "      <td>COC(=O)C(c1ccccc1Cl)N1CCc2sccc2C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CHEMBL234951</td>\n",
              "      <td>3.37</td>\n",
              "      <td>OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...</td>\n",
              "      <td>O=C(NC1Cc2ccccc2N(C[C@@H](O)CO)C1=O)c1cc2cc(Cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CHEMBL565079</td>\n",
              "      <td>3.10</td>\n",
              "      <td>Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...</td>\n",
              "      <td>Cc1cccc(CC(NC(=O)c2cc(C(C)(C)C)nn2C)C(=O)NCC#N)c1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                 standartize_smiles\n",
              "0           0  ...            Cn1c(CN2CCN(c3ccc(Cl)cc3)CC2)nc2ccccc21\n",
              "1           1  ...  COc1cc(OC)c(S(=O)(=O)N2c3ccccc3CCC2C)cc1NC(=O)...\n",
              "2           2  ...                  COC(=O)C(c1ccccc1Cl)N1CCc2sccc2C1\n",
              "3           3  ...  O=C(NC1Cc2ccccc2N(C[C@@H](O)CO)C1=O)c1cc2cc(Cl...\n",
              "4           4  ...  Cc1cccc(CC(NC(=O)c2cc(C(C)(C)C)nn2C)C(=O)NCC#N)c1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fcf-ej4eShYT",
        "outputId": "44b19902-28f4-40d6-ae36-37fed03d1481"
      },
      "source": [
        "lst = ['C', 'n', '1', 'c', '(', 'N', '2', ')', '3', 'l', '4', '\\t', '5', 'O', 'S', '=', '6', 's', '7', '[', '@', 'H', ']', '8', '#', '9', '-', '0', 'o', 'F', 'B', 'r', '+', '\\\\', '/', 'P', 'I', 'i', 'e', '.', '%']\n",
        "str = \"\"\n",
        "for i in lst:\n",
        "    str = str + '|' + i\n",
        "str"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|C|n|1|c|(|N|2|)|3|l|4|\\t|5|O|S|=|6|s|7|[|@|H|]|8|#|9|-|0|o|F|B|r|+|\\\\|/|P|I|i|e|.|%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ohMyGeS2HW"
      },
      "source": [
        "class data_preprocessor:\n",
        "  def __init__(self):\n",
        "    self.symbols = []\n",
        "    self.seq_length = -1\n",
        "    self.seq_lengths = []\n",
        "\n",
        "\n",
        "  def preprocess_data(self, df):\n",
        "      self.tokenization(df)\n",
        "      self.create_vocab()\n",
        "      X = []\n",
        "      for x in df.tokens:\n",
        "          x = x.split(' ')\n",
        "          x = self.seq2ind(x)\n",
        "          x_eq = self.pad_input(x)\n",
        "          X.append(x_eq)\n",
        "      y = df.exp\n",
        "      \n",
        "      return X, y\n",
        "\n",
        "\n",
        "  def tokenization(self, df):\n",
        "    \"\"\"\n",
        "    Tokenize all SMILES in df dataframe\n",
        "    \"\"\"\n",
        "    df['tokens'] = df['standartize_smiles'].apply(self.smiles_tokenization)\n",
        "    self.seq_length = max(self.seq_lengths) #wtf\n",
        "    return df\n",
        "\n",
        "  def smiles_tokenization(self, smi: str):\n",
        "    \"\"\"\n",
        "    Tokenize a SMILES molecule or reaction\n",
        "    \"\"\"\n",
        "    # https://docs.python.org/3/library/re.html\n",
        "    import re\n",
        "    pattern = \"Cl?|Br?|I|Se?|H|O|N|P|F|cl?|br?|i|se?|h|o|n|p|f|[0-9]|#|@|\\(|\\)|\\[|\\]|\\-|%|\\/|\\\\\\\\|\\.|=|\\+\"\n",
        "    regex = re.compile(pattern)\n",
        "    \n",
        "    tokens = regex.findall(smi)\n",
        "    self.seq_lengths.append(len(tokens))\n",
        "    self.symbols += tokens\n",
        "    self.symbols = list(set(self.symbols))\n",
        "    #print(smi)\n",
        "    #print(\"\".join(tokens))\n",
        "    assert smi == ''.join(tokens)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "  def create_vocab(self):\n",
        "    \"\"\"\n",
        "    Create vocabulary of the symbols\n",
        "    \"\"\"\n",
        "    self.token2idx = {o:i for i,o in enumerate(self.symbols)}\n",
        "    self.idx2token = {i:o for i,o in enumerate(self.symbols)}\n",
        "\n",
        "  def seq2ind(self, seq: list):\n",
        "    return [self.token2idx[x] for x in seq] #map of tokens\n",
        "\n",
        "  def pad_input(self, seq: list):\n",
        "    features = np.zeros((self.seq_length),dtype=int)\n",
        "    features[-len(seq):] = np.array(seq)[:self.seq_length]\n",
        "    return features\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSKyqBWwLADC"
      },
      "source": [
        "st = data_preprocessor()\n",
        "X, y = st.preprocess_data(data)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKEFzdRzY-XO"
      },
      "source": [
        "# –î–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHk9oF2wY9cz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju9QEVNrZOKS"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUbZnexs6Cba",
        "outputId": "d362ba01-29eb-4a9b-f21c-23a870a18db2"
      },
      "source": [
        " np.array(y_train.values)[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.78,  0.87,  3.14,  3.9 ,  1.01,  2.7 ,  2.63,  1.5 , -0.06,\n",
              "        0.76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0QpeYtKagbZ"
      },
      "source": [
        "# –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Wl5z6m3XX4"
      },
      "source": [
        "\n",
        "  * –ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ numpy array\n",
        "  * —Å–¥–µ–ª–∞–π—Ç–µ torch.tensor –ø—Ä–∏ –ø–æ–º–æ—â–∏ torch.from_numpy\n",
        "  * —Å–æ–∑–¥–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç torch.utils.data.TensorDataset\n",
        "  * —Å–¥–µ–ª–∞–π—Ç–µ –∏–∑ –Ω–µ–≥–æ DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlBP94hGaf30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a362be-1dd3-4310-bc36-bfacf56866ce"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 400\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size)\n",
        "\n",
        "test_loader = DataLoader(test_data, batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2940, 265)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOhd3tNi09Zj",
        "outputId": "6466e009-8279-4b46-9b9c-637ab54ee5ae"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.78 0.87 3.14 ... 3.6  0.2  3.8 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMVioQNg1ytm",
        "outputId": "44b156fb-cee4-4665-9021-2efad518ef51"
      },
      "source": [
        "iter(train_loader).next()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0,  0,  0,  ...,  1,  1,  9],\n",
              "         [ 0,  0,  0,  ...,  9, 15,  5],\n",
              "         [ 0,  0,  0,  ..., 11, 11,  9],\n",
              "         ...,\n",
              "         [ 0,  0,  0,  ..., 18,  1, 25],\n",
              "         [ 0,  0,  0,  ...,  5, 18,  5],\n",
              "         [ 0,  0,  0,  ..., 11,  9, 25]]),\n",
              " tensor([ 3.7800,  0.8700,  3.1400,  3.9000,  1.0100,  2.7000,  2.6300,  1.5000,\n",
              "         -0.0600,  0.7600,  1.5600,  2.6800,  2.4000, -1.0300, -0.6500,  3.3300,\n",
              "          0.6800,  1.3100,  3.1000,  0.5100,  3.8000,  0.6400,  1.9700,  2.4000,\n",
              "          2.8000,  1.3000,  3.0200,  2.6000,  2.8600, -0.8700,  2.7000,  3.8000,\n",
              "          3.0600,  4.0000, -0.3700,  1.9000, -0.5100,  1.1800,  2.1400,  1.2100,\n",
              "          3.6000,  1.5000,  3.4000,  2.9000,  0.9700, -0.4000,  2.2100,  3.0800,\n",
              "          3.6000,  2.4100,  0.2300,  1.7300,  2.2800,  2.1000,  3.0100,  2.6900,\n",
              "          2.5800,  2.5000,  2.6000,  0.9100,  3.5000,  2.4100,  3.8600,  2.2300,\n",
              "          3.6600,  1.4000,  3.3200,  1.1800,  0.7800,  1.7400,  2.8000,  3.7000,\n",
              "          1.0300,  2.9200,  2.4400,  2.4000,  3.1500,  3.2000,  0.6900,  2.3000,\n",
              "          1.9900,  2.0000,  2.9000,  2.6300,  2.7000,  4.3000,  1.7300,  1.1000,\n",
              "          2.2600,  0.8900,  3.4000,  2.8000,  3.2300,  2.6900,  3.8800,  3.9700,\n",
              "          3.7000,  3.1400,  3.3700,  3.4200,  1.9000,  1.7200,  1.8300,  2.3700,\n",
              "          0.3500,  2.8000,  4.2000,  1.7100,  1.5000,  3.2000,  3.4200,  2.4000,\n",
              "          3.4200,  1.8400,  2.1200,  3.5000,  3.7800,  1.7000,  3.1000,  2.7000,\n",
              "          2.2600, -0.8400, -0.7800,  3.0500,  0.6300,  0.1500,  1.7300,  2.7000,\n",
              "          1.6500,  3.0000,  2.9000,  1.2500,  0.4700,  2.4100,  2.3500,  2.9000,\n",
              "          0.7000, -0.0300,  2.9900,  2.3200,  2.2000,  3.6000,  2.7000,  2.3700,\n",
              "          0.8800,  0.2100,  3.0500,  2.0000,  3.7000,  2.6400,  2.8700,  1.1300,\n",
              "          2.6300,  3.1200, -0.2000,  1.6800,  1.9400,  2.5900,  4.1000,  2.3700,\n",
              "          3.9000,  3.5000,  0.0600,  2.8900,  3.8200, -1.0200,  2.5000,  2.8000,\n",
              "          3.0000,  3.6000,  4.3600,  0.0200,  2.4000,  3.5000,  0.3000,  1.6200,\n",
              "          1.1200,  4.2000,  2.9900,  3.0200,  0.2200,  3.5000,  2.7000,  2.2300,\n",
              "          2.2500,  1.0700,  0.7000,  0.9000, -0.9400,  3.1700,  2.8800,  3.0000,\n",
              "          3.7000,  2.1000, -0.9600,  2.4100,  0.7600,  1.8400,  4.2800,  0.1800,\n",
              "          1.2500,  3.0000,  1.7000,  3.7000,  3.7000,  3.7000,  3.5600,  1.4000,\n",
              "          3.6200,  2.6000,  2.6700,  2.4100,  1.2600,  3.4300,  1.9200,  2.1900,\n",
              "          1.7000,  1.6800,  1.2200,  1.9400,  1.7200,  3.2700,  1.0300,  0.2000,\n",
              "          2.5800,  2.1800,  2.7900,  2.2400,  3.9800,  2.1700,  2.9100,  3.2000,\n",
              "          3.4700,  0.8500,  2.6300,  3.3600,  2.1000,  3.1000,  2.6100,  3.1100,\n",
              "          3.2100,  2.5500,  2.4700,  3.0700,  3.8300, -0.0400,  2.8100,  3.9900,\n",
              "          0.2300,  3.3000,  3.0200,  1.1000,  3.3700, -1.0100,  2.6700,  0.6500,\n",
              "          3.7700,  2.5800,  1.9000,  2.9000,  3.2900,  3.3000,  0.3000,  2.4000,\n",
              "          1.3300,  1.1000,  1.3300,  2.4000,  2.6900,  3.5200,  3.0000,  4.2100,\n",
              "          2.5500,  1.4000,  3.3000,  2.7100,  2.3700,  1.9500,  3.2500,  3.0000,\n",
              "          2.0900,  0.3700,  1.3900,  3.3000, -0.4900,  3.8000,  1.5000,  3.3500,\n",
              "          0.0500,  1.1500,  2.5900,  3.2000,  0.9800,  2.8300,  1.8100,  2.0300,\n",
              "          3.8000,  2.6700,  1.5800,  4.5000,  2.4300,  2.8200,  2.1500,  2.5000,\n",
              "          1.4000,  2.3200,  1.4900,  0.8100,  4.4600,  3.6700,  2.4500,  0.9300,\n",
              "          2.8300,  3.6100,  2.0900,  2.3300,  1.5000,  3.1700,  3.5900,  0.6000,\n",
              "          3.5300,  1.9500,  3.6000,  4.2100,  1.4500,  2.2500,  1.9000,  2.4800,\n",
              "          3.6000,  3.6200,  0.9100,  3.0000,  1.6800,  2.6000,  1.3800,  2.8700,\n",
              "          2.1000,  3.0200,  3.3500,  0.8900,  0.7000,  3.3000,  2.4000,  0.8700,\n",
              "          1.2700,  3.8500,  1.4600,  2.1000,  2.5300,  2.4800,  2.7500,  2.0200,\n",
              "          2.1700,  1.5200,  1.9100,  3.5300,  3.8000,  2.7300,  3.7000,  0.4000,\n",
              "          4.1700,  1.0000,  3.3100,  1.2800,  3.0000,  3.1000,  1.3800,  2.0100,\n",
              "          4.2000,  2.8500,  1.4200, -0.7000,  0.6000,  4.2400,  1.5500,  0.2700,\n",
              "          3.4000,  2.0000,  1.6400,  4.2000,  3.1000,  2.1400,  3.2000,  3.0700,\n",
              "          3.3000,  2.8200,  2.9800,  4.4300,  1.0000,  2.1300,  1.9500,  1.3200,\n",
              "          1.3600,  3.2500,  0.9800,  2.7400,  1.6200,  3.8400,  0.5300,  2.8400],\n",
              "        dtype=torch.float64)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjMcmrd8EUq5",
        "outputId": "c0c6ed82-c366-41f4-861c-c5e31f28268b"
      },
      "source": [
        "for now in train_loader:\n",
        "    print(type(now))\n",
        "    print(len(now))\n",
        "    print(now)\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "2\n",
            "[tensor([[ 0,  0,  0,  ...,  1,  1,  9],\n",
            "        [ 0,  0,  0,  ...,  9, 15,  5],\n",
            "        [ 0,  0,  0,  ..., 11, 11,  9],\n",
            "        ...,\n",
            "        [ 0,  0,  0,  ..., 18,  1, 25],\n",
            "        [ 0,  0,  0,  ...,  5, 18,  5],\n",
            "        [ 0,  0,  0,  ..., 11,  9, 25]]), tensor([ 3.7800,  0.8700,  3.1400,  3.9000,  1.0100,  2.7000,  2.6300,  1.5000,\n",
            "        -0.0600,  0.7600,  1.5600,  2.6800,  2.4000, -1.0300, -0.6500,  3.3300,\n",
            "         0.6800,  1.3100,  3.1000,  0.5100,  3.8000,  0.6400,  1.9700,  2.4000,\n",
            "         2.8000,  1.3000,  3.0200,  2.6000,  2.8600, -0.8700,  2.7000,  3.8000,\n",
            "         3.0600,  4.0000, -0.3700,  1.9000, -0.5100,  1.1800,  2.1400,  1.2100,\n",
            "         3.6000,  1.5000,  3.4000,  2.9000,  0.9700, -0.4000,  2.2100,  3.0800,\n",
            "         3.6000,  2.4100,  0.2300,  1.7300,  2.2800,  2.1000,  3.0100,  2.6900,\n",
            "         2.5800,  2.5000,  2.6000,  0.9100,  3.5000,  2.4100,  3.8600,  2.2300,\n",
            "         3.6600,  1.4000,  3.3200,  1.1800,  0.7800,  1.7400,  2.8000,  3.7000,\n",
            "         1.0300,  2.9200,  2.4400,  2.4000,  3.1500,  3.2000,  0.6900,  2.3000,\n",
            "         1.9900,  2.0000,  2.9000,  2.6300,  2.7000,  4.3000,  1.7300,  1.1000,\n",
            "         2.2600,  0.8900,  3.4000,  2.8000,  3.2300,  2.6900,  3.8800,  3.9700,\n",
            "         3.7000,  3.1400,  3.3700,  3.4200,  1.9000,  1.7200,  1.8300,  2.3700,\n",
            "         0.3500,  2.8000,  4.2000,  1.7100,  1.5000,  3.2000,  3.4200,  2.4000,\n",
            "         3.4200,  1.8400,  2.1200,  3.5000,  3.7800,  1.7000,  3.1000,  2.7000,\n",
            "         2.2600, -0.8400, -0.7800,  3.0500,  0.6300,  0.1500,  1.7300,  2.7000,\n",
            "         1.6500,  3.0000,  2.9000,  1.2500,  0.4700,  2.4100,  2.3500,  2.9000,\n",
            "         0.7000, -0.0300,  2.9900,  2.3200,  2.2000,  3.6000,  2.7000,  2.3700,\n",
            "         0.8800,  0.2100,  3.0500,  2.0000,  3.7000,  2.6400,  2.8700,  1.1300,\n",
            "         2.6300,  3.1200, -0.2000,  1.6800,  1.9400,  2.5900,  4.1000,  2.3700,\n",
            "         3.9000,  3.5000,  0.0600,  2.8900,  3.8200, -1.0200,  2.5000,  2.8000,\n",
            "         3.0000,  3.6000,  4.3600,  0.0200,  2.4000,  3.5000,  0.3000,  1.6200,\n",
            "         1.1200,  4.2000,  2.9900,  3.0200,  0.2200,  3.5000,  2.7000,  2.2300,\n",
            "         2.2500,  1.0700,  0.7000,  0.9000, -0.9400,  3.1700,  2.8800,  3.0000,\n",
            "         3.7000,  2.1000, -0.9600,  2.4100,  0.7600,  1.8400,  4.2800,  0.1800,\n",
            "         1.2500,  3.0000,  1.7000,  3.7000,  3.7000,  3.7000,  3.5600,  1.4000,\n",
            "         3.6200,  2.6000,  2.6700,  2.4100,  1.2600,  3.4300,  1.9200,  2.1900,\n",
            "         1.7000,  1.6800,  1.2200,  1.9400,  1.7200,  3.2700,  1.0300,  0.2000,\n",
            "         2.5800,  2.1800,  2.7900,  2.2400,  3.9800,  2.1700,  2.9100,  3.2000,\n",
            "         3.4700,  0.8500,  2.6300,  3.3600,  2.1000,  3.1000,  2.6100,  3.1100,\n",
            "         3.2100,  2.5500,  2.4700,  3.0700,  3.8300, -0.0400,  2.8100,  3.9900,\n",
            "         0.2300,  3.3000,  3.0200,  1.1000,  3.3700, -1.0100,  2.6700,  0.6500,\n",
            "         3.7700,  2.5800,  1.9000,  2.9000,  3.2900,  3.3000,  0.3000,  2.4000,\n",
            "         1.3300,  1.1000,  1.3300,  2.4000,  2.6900,  3.5200,  3.0000,  4.2100,\n",
            "         2.5500,  1.4000,  3.3000,  2.7100,  2.3700,  1.9500,  3.2500,  3.0000,\n",
            "         2.0900,  0.3700,  1.3900,  3.3000, -0.4900,  3.8000,  1.5000,  3.3500,\n",
            "         0.0500,  1.1500,  2.5900,  3.2000,  0.9800,  2.8300,  1.8100,  2.0300,\n",
            "         3.8000,  2.6700,  1.5800,  4.5000,  2.4300,  2.8200,  2.1500,  2.5000,\n",
            "         1.4000,  2.3200,  1.4900,  0.8100,  4.4600,  3.6700,  2.4500,  0.9300,\n",
            "         2.8300,  3.6100,  2.0900,  2.3300,  1.5000,  3.1700,  3.5900,  0.6000,\n",
            "         3.5300,  1.9500,  3.6000,  4.2100,  1.4500,  2.2500,  1.9000,  2.4800,\n",
            "         3.6000,  3.6200,  0.9100,  3.0000,  1.6800,  2.6000,  1.3800,  2.8700,\n",
            "         2.1000,  3.0200,  3.3500,  0.8900,  0.7000,  3.3000,  2.4000,  0.8700,\n",
            "         1.2700,  3.8500,  1.4600,  2.1000,  2.5300,  2.4800,  2.7500,  2.0200,\n",
            "         2.1700,  1.5200,  1.9100,  3.5300,  3.8000,  2.7300,  3.7000,  0.4000,\n",
            "         4.1700,  1.0000,  3.3100,  1.2800,  3.0000,  3.1000,  1.3800,  2.0100,\n",
            "         4.2000,  2.8500,  1.4200, -0.7000,  0.6000,  4.2400,  1.5500,  0.2700,\n",
            "         3.4000,  2.0000,  1.6400,  4.2000,  3.1000,  2.1400,  3.2000,  3.0700,\n",
            "         3.3000,  2.8200,  2.9800,  4.4300,  1.0000,  2.1300,  1.9500,  1.3200,\n",
            "         1.3600,  3.2500,  0.9800,  2.7400,  1.6200,  3.8400,  0.5300,  2.8400],\n",
            "       dtype=torch.float64)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behdLk6OSV7j"
      },
      "source": [
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG8IWTg66Z2d"
      },
      "source": [
        "## –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6UrDr7hL7oT"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UetcnULxMxT_"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWtvl40E6cl5"
      },
      "source": [
        "class  CharCNN(nn.Module):\n",
        "    def __init__(self, seq_len: int):\n",
        "        super(CharCNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(len(st.token2idx) + 1, 400)\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(seq_len, 128, kernel_size=7, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(16768, 1)\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv1(x)\n",
        "       \n",
        "        # collapse\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # linear layer\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQv971kHHFf-"
      },
      "source": [
        "model = CharCNN(st.seq_length)\n",
        "model = model.to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), \n",
        "                       lr=0.001\n",
        "                       )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl0dxvR0uViu"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-LIe7s1zBeD"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpmt8zF5bAUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea1bc98-bbc7-4772-bbc6-1a0198eae8b7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "for it_now, labels in tqdm(train_loader):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    it_now = it_now.to(device)\n",
        "    labels = labels.to(device).view(-1,1)\n",
        "\n",
        "    output = model(it_now.long())\n",
        "\n",
        "\n",
        "    loss = criterion(output.float(), labels.float())\n",
        "\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:36<00:00,  4.56s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c7pnVvWy5sP",
        "outputId": "792312b7-d0c1-4b6f-d55d-354395812a69"
      },
      "source": [
        "print(type(labels))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221EQCGW6pUW"
      },
      "source": [
        "**TO-DO**\n",
        "1. –°–æ–∑–¥–∞–π—Ç–µ optimizer, criterion\n",
        "2. –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ GPU\n",
        "3. –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—É –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cVoymaYbyaJ"
      },
      "source": [
        "## RNN\n",
        "\n",
        "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "\n",
        "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
        "\n",
        "## LSTM\n",
        "\n",
        "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNUTembXcSNs"
      },
      "source": [
        "–ü–æ—á–∏—Ç–∞—Ç—å - https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å - https://stepik.org/course/54098/syllabus (–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1rbiVtcbUo2"
      },
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentNet, self).__init__() #\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers #?\n",
        "        self.hidden_dim = hidden_dim #?\n",
        "        \n",
        "        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å—Å—è –¥–ª—è \n",
        "        # –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–∞\n",
        "        # nn.Embedding\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim=embedding_dim)\n",
        "\n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º LSTM —Å–ª–æ–π\n",
        "        # nn.LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = drop_prob)\n",
        "\n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º DropOut –º–µ–∂–¥—É —Å–ª–æ—è–º–∏ –Ω–µ–π—Ä–æ–Ω–∫–∏\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        # –õ–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –¥–ª—è –≤—ã–≤–æ–¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è \n",
        "        self.fc = nn.Linear(512, output_size)\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self, x):#, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long()\n",
        "\n",
        "\n",
        "        # —Å–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "    \n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKcEeGB4vU9"
      },
      "source": [
        "vocab_size = len(st.token2idx) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 512\n",
        "n_layers = 2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUVukji641Pl"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7kiseuF4t6B"
      },
      "source": [
        "**TO-DO**\n",
        "1. –°–æ–∑–¥–∞–π—Ç–µ optimizer, criterion\n",
        "2. –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ GPU\n",
        "3. –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—É –æ–±—É—á–µ–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50HBfp6k2NaA",
        "outputId": "25f93c04-d0ba-410e-807f-5ef8f7084e21"
      },
      "source": [
        "batch_size"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXsB-YLF7Cu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da0edcb-1d3a-42f2-b2a0-cca10ea53fdb"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St2IntIqfbX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f32c51-57d5-4fbb-e4c9-a599839cb334"
      },
      "source": [
        "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model = model.to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), \n",
        "                       lr=0.001\n",
        "                       )\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0\n",
        "\n",
        "    for it_now, labels in tqdm(train_loader):\n",
        "        optimizer.zero_grad() #–æ–±–Ω—É–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö\n",
        "        it_now = it_now.to(device)\n",
        "        labels = labels.to(device) #–≤—Å–µ –Ω–∞ –≥–ø—É\n",
        "        output = model(it_now.long())[0]\n",
        "        '''print(len(output), len(labels))\n",
        "        print(type(output[0]), type(labels[0]))\n",
        "        print(output, labels, sep='\\n')'''\n",
        "        loss = criterion(output.float(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    print(f\"Epoch {epoch} - Training loss: {running_loss/len(train_loader)}\")\n",
        "    train_loss.append(running_loss)    "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:08<00:00, 46.09s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 2.462368741631508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:03<00:00, 45.38s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 1.5060921609401703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:13<00:00, 46.65s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 1.442159816622734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:06<00:00, 45.82s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training loss: 1.459856629371643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:18<00:00, 47.28s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training loss: 1.4376540631055832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:16<00:00, 47.09s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 - Training loss: 1.4325450956821442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:07<00:00, 45.98s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 - Training loss: 1.445497453212738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:15<00:00, 46.99s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 - Training loss: 1.4253544509410858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:06<00:00, 45.82s/it]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 - Training loss: 1.4186868965625763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [06:22<00:00, 47.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 - Training loss: 1.4342459291219711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWzPkKkXRGCT"
      },
      "source": [
        "# –£–ª—É—á—à–µ–Ω–∏—è\n",
        "\n",
        "1. (–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è) –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "–ï—Å–ª–∏ —É –≤–∞—Å –Ω–∞ —Ä—É–∫–∞—Ö –µ—Å—Ç—å –Ω–µ–±–æ–ª—å—à–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ —É –Ω–∞—Å), —Ç–æ –º–æ–∂–Ω–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ. \n",
        "\n",
        "–í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–µ—Ç–æ–¥–æ–º, –∫–æ—Ç–æ—Ä—ã–π –º—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ. \n",
        "\n",
        "–î–ª—è c–æ–∑–¥–∞–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö SMILES –≤ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `Chem.MolToSmiles –∏ Chem.MolFromSmiles` —Å —Ñ–ª–∞–≥–æ–º `doRandom`.\n",
        "\n",
        "2. –£–≥–ª—É–±–∏—Ç—å –º–æ–¥–µ–ª—å (–±–æ–ª—å—à–µ lstm —Å–ª–æ–µ–≤)\n",
        "\n",
        "3. –ó–∞–º–µ–Ω–∏—Ç—å lstm –Ω–∞ bidirectional lstm (https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "\n",
        "4. –ü–æ–¥–æ–±—Ä–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Ä—É–∫–∞–º–∏ –∏–ª–∏ GridSearch). embedding_dim, hidden_dim, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ LSTM —Å–ª–æ–µ–≤\n",
        "\n",
        "5. –°–¥–µ–ª–∞—Ç—å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é\n",
        "\n",
        "6. –î–æ–±–∞–≤–∏—Ç—å EarlyStopping\n",
        "\n",
        "7. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–π—Å—Ç–≤–∞ –º–æ–ª–µ–∫—É–ª –∏–∑ –±–µ–π–∑–ª–∞–π–Ω–∞ –∫–∞–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä\n",
        "–ü—Ä–∏–º–µ—Ä:\n",
        "https://github.com/NU-CUCIS/CheMixNet\n",
        "\n",
        "8. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å one-hot-encoding –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlE7XgyrRCXY"
      },
      "source": [
        "smi = 'COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl'\n",
        "random_equivalent_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smi), doRandom=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GNdsds7aR-Pj",
        "outputId": "bce8ef6c-e9d4-45d6-f471-bab880d037c3"
      },
      "source": [
        "random_equivalent_smiles"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'COC([C@@H](N1CCc2c(ccs2)C1)c1c(cccc1)Cl)=O'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxTsiKsbSMp_"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}